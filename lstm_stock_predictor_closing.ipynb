{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# LSTM Stock Predictor Using Closing Prices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "##  Data Preparation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import hvplot.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the random seed for reproducibility\n",
    "# Note: This is for the homework solution, but it is good practice to comment this out and run multiple experiments to evaluate your model\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import random\n",
    "random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fear and greed sentiment data for Bitcoin\n",
    "df = pd.read_csv('btc_sentiment.csv', index_col=\"date\", infer_datetime_format=True, parse_dates=True)\n",
    "df = df.drop(columns=\"fng_classification\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the historical closing prices for Bitcoin\n",
    "df2 = pd.read_csv('btc_historic.csv', index_col=\"Date\", infer_datetime_format=True, parse_dates=True)['Close']\n",
    "df2 = df2.sort_index()\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the data into a single DataFrame\n",
    "df = df.join(df2, how=\"inner\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function accepts the column number for the features (X) and the target (y)\n",
    "# It chunks the data up with a rolling window of Xt-n to predict Xt\n",
    "# It returns a numpy array of X any y\n",
    "def window_data(df, window, feature_col_number, target_col_number):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(df) - window - 1):\n",
    "        features = df.iloc[i:(i + window), feature_col_number]\n",
    "        target = df.iloc[(i + window), target_col_number]\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "    return np.array(X), np.array(y).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict Closing Prices using a 10 day window of previous closing prices\n",
    "# Then, experiment with window sizes anywhere from 1 to 10 and see how the model performance changes\n",
    "window_size = 10\n",
    "\n",
    "# Column index 0 is the 'fng_value' column\n",
    "# Column index 1 is the `Close` column\n",
    "feature_column = 1\n",
    "target_column = 1\n",
    "X, y = window_data(df, window_size, feature_column, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 70% of the data for training and the remaineder for testing\n",
    "split = int(0.7 * len(X))\n",
    "\n",
    "X_train = X[: split]\n",
    "X_test = X[split:]\n",
    "\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Use the MinMaxScaler to scale data between 0 and 1.\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the MinMaxScaler object with the features data X\n",
    "scaler.fit(X)\n",
    "\n",
    "# Scale the features training and testing sets\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit the MinMaxScaler object with the target data Y\n",
    "scaler.fit(y)\n",
    "\n",
    "# Scale the target training and testing sets\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the features for the model\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "print (f\"X_train sample values:\\n{X_train[:5]} \\n\")\n",
    "print (f\"X_test sample values:\\n{X_test[:5]}\")"
   ]
  },
  {
   "source": [
    "## Build and Train the LSTM RNN"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}